{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 Lab Assignment: Decision Analysis, Model Comparison, and Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "In this lab, you will use decision analytic tools to frame a business problem, analyze alternatives, compare different models, and implement ensemble models to improve decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Installations\n",
    "**Objective:** Ensure all necessary packages are installed and imported for the lab.\n",
    "\n",
    "**Tasks:**\n",
    "1. Install required Python packages: Scikit-learn, Pandas, Numpy, Matplotlib, and Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (1.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (0.13.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'c:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "%pip install scikit-learn pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Libraries\n",
    "**Objective:** Import all necessary libraries for data manipulation, decision analysis, model comparison, and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define a Business Problem\n",
    "**Objective:** Choose a relevant business problem and set clear objectives and decision criteria.\n",
    "\n",
    "**Tasks:**\n",
    "1. Define the business problem (e.g., customer churn prediction).\n",
    "2. Set objectives and decision criteria (e.g., minimize customer churn rate, maximize retention)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Problem:** Predict whether a customer will churn (leave the company) based on their characteristics and past behavior.\n",
    "\n",
    "**Objective:** Use predictive modeling to identify customers at high risk of churn so that targeted retention strategies can be implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load and Explore Dataset\n",
    "**Objective:** Gain a preliminary understanding of the dataset to be used for decision analysis.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Load the Dataset:** Import the dataset into a Pandas DataFrame.\n",
    "2. **Inspect the Data:** Use Pandas functions to inspect the first few rows, check for missing values, and understand the data types.\n",
    "3. **Summary Statistics:** Generate summary statistics for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  Age  Gender  Tenure  MonthlyCharges  TotalCharges  \\\n",
      "0           1   45    Male      12           70.35        804.15   \n",
      "1           2   34  Female      24           56.95       1354.80   \n",
      "2           3   23  Female       5           29.85        149.15   \n",
      "3           4   57  Female      15          104.75       1571.65   \n",
      "4           5   42    Male      36           53.85       1938.75   \n",
      "\n",
      "  InternetService        Contract              PaymentMethod Churn  \n",
      "0     Fiber optic  Month-to-month           Electronic check   Yes  \n",
      "1             DSL        One year  Bank transfer (automatic)    No  \n",
      "2             DSL  Month-to-month               Mailed check   Yes  \n",
      "3     Fiber optic  Month-to-month           Electronic check    No  \n",
      "4             DSL        Two year    Credit card (automatic)    No  \n",
      "CustomerID         0\n",
      "Age                0\n",
      "Gender             0\n",
      "Tenure             0\n",
      "MonthlyCharges     0\n",
      "TotalCharges       0\n",
      "InternetService    0\n",
      "Contract           0\n",
      "PaymentMethod      0\n",
      "Churn              0\n",
      "dtype: int64\n",
      "       CustomerID        Age     Tenure  MonthlyCharges  TotalCharges\n",
      "count   30.000000  30.000000  30.000000        30.00000     30.000000\n",
      "mean    15.500000  39.300000  14.000000        66.75000   1010.591667\n",
      "std      8.803408  11.820934   8.267093        27.11688    715.539341\n",
      "min      1.000000  19.000000   2.000000        20.00000     39.650000\n",
      "25%      8.250000  30.250000   7.250000        54.10000    404.075000\n",
      "50%     15.500000  38.500000  13.000000        70.62500    931.825000\n",
      "75%     22.750000  46.750000  19.750000        88.07500   1530.212500\n",
      "max     30.000000  63.000000  36.000000       109.10000   2625.500000\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('customer_churn_data.csv')\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Generate summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Preparation\n",
    "**Objective:** Prepare the data for modeling by handling missing values, encoding categorical variables, and splitting into training and test sets.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Handle Missing Values:** Fill or drop missing values as appropriate.\n",
    "2. **Encode Categorical Variables:** Use one-hot encoding or label encoding for categorical features.\n",
    "3. **Split Data:** Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Churn'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df, drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Split the data into features and target\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mChurn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChurn\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Churn'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Example of data preparation steps\n",
    "df = df.dropna()\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f'Training set size: {X_train.shape}')\n",
    "print(f'Test set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create a Decision Tree\n",
    "**Objective:** Build a decision tree to explore different decision paths and analyze potential outcomes.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Train a Decision Tree:** Use the training data to train a decision tree model.\n",
    "2. **Visualize the Decision Tree:** Plot the decision tree to understand decision paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Decision Tree\n",
    "tree_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Visualize the Decision Tree\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(tree_model, feature_names=X.columns, class_names=['No Churn', 'Churn'], filled=True)\n",
    "plt.title('Decision Tree for Customer Churn Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model Comparison\n",
    "**Objective:** Compare different models using performance metrics to determine the best model for the decision-making process.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Train Different Models:** Use Random Forest, Gradient Boosting, and other models for comparison.\n",
    "2. **Evaluate Models:** Use accuracy, precision, recall, and F1 score to compare model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Train a Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print('Random Forest Classification Report')\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "print('Gradient Boosting Classification Report')\n",
    "print(classification_report(y_test, gb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Implement Ensemble Models\n",
    "**Objective:** Use ensemble techniques to combine models and improve decision-making accuracy.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Use Voting Classifier:** Combine Decision Tree, Random Forest, and Gradient Boosting using Voting Classifier.\n",
    "2. **Evaluate Ensemble Model:** Compare the ensemble model's performance with individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Voting Classifier to combine models\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('dt', tree_model), ('rf', rf_model), ('gb', gb_model)],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the ensemble model\n",
    "voting_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "print('Ensemble Model (Voting Classifier) Classification Report')\n",
    "print(classification_report(y_test, voting_pred))\n",
    "\n",
    "# Confusion Matrix for Ensemble Model\n",
    "conf_matrix = confusion_matrix(y_test, voting_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Ensemble Model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Summary and Discussion\n",
    "**Objective:** Reflect on the effectiveness of different models and ensemble techniques and discuss their applications in business decision-making.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Compare Model Performance:** Discuss the results from individual models and the ensemble model.\n",
    "2. **Business Implications:** Describe how model comparison and ensemble techniques can improve business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Submission\n",
    "**Deliverables:**\n",
    "- Jupyter Notebook (.ipynb) with all code, visualizations, and model evaluations.\n",
    "- A brief report (1-2 paragraphs) summarizing the findings, comparing model performance, and discussing the use of ensemble models in decision-making.\n",
    "\n",
    "**Deadline:** Submit your completed notebook and report to the course portal by the end of class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
