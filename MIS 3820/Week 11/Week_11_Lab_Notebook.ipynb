{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 11 Lab Assignment: Text Analytics and Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "In this lab, you will explore text analytics and evaluate the performance of predictive models using various metrics. The lab focuses on text data cleaning, building models, and assessing their performance with accuracy, precision, recall, F1 score, and ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Installations\n",
    "**Objective:** Ensure all necessary packages are installed and imported for the lab.\n",
    "\n",
    "**Tasks:**\n",
    "1. Install required Python packages: Scikit-learn, Pandas, Numpy, Matplotlib, Seaborn, and NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (1.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (0.13.2)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (3.1.2)\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 97.9/97.9 KB 5.5 MB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2024.7.24-cp39-cp39-win_amd64.whl (269 kB)\n",
      "     -------------------------------------- 269.7/269.7 KB 5.5 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.4/78.4 KB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.7 nltk-3.9.1 regex-2024.7.24 tqdm-4.66.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'c:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "%pip install scikit-learn pandas numpy matplotlib seaborn nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Libraries\n",
    "**Objective:** Import all necessary libraries for data manipulation, text processing, modeling, and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix, roc_curve\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and Explore Text Data\n",
    "**Objective:** Gain a preliminary understanding of the text dataset to be used for analysis.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Load the Dataset:** Import the dataset into a Pandas DataFrame.\n",
    "2. **Inspect the Data:** Use Pandas functions to inspect the first few rows, check for missing values, and understand the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     label\n",
      "0  The product quality is really good and I am sa...  positive\n",
      "1  I had a terrible experience with the customer ...  negative\n",
      "2  The delivery was fast and the packaging was ex...  positive\n",
      "3  The website was very confusing and hard to nav...  negative\n",
      "4  I love the variety of products available and t...  positive\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('text_data.csv')\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Text Data Cleaning\n",
    "**Objective:** Prepare the text data by cleaning and tokenizing it.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Remove Stop Words:** Use NLTK to remove common stop words from the text.\n",
    "2. **Tokenization:** Split text into individual words (tokens).\n",
    "3. **Vectorization:** Convert text into numerical format using TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      product quality really good satisfied purchase.\n",
      "1    terrible experience customer service, disappoi...\n",
      "2                   delivery fast packaging excellent.\n",
      "3                     website confusing hard navigate.\n",
      "4    love variety products available prices reasona...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Text cleaning and tokenization\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "print(df['cleaned_text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Split Data and Apply TF-IDF\n",
    "**Objective:** Convert the cleaned text data into numerical format and split it into training and testing sets.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Apply TF-IDF Vectorization:** Use TfidfVectorizer to convert text to numerical features.\n",
    "2. **Split Data:** Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (14, 98)\n",
      "Test set size: (6, 98)\n"
     ]
    }
   ],
   "source": [
    "# Apply TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df['cleaned_text']).toarray()\n",
    "y = df['label']  # Assuming 'label' is the target column\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f'Training set size: {X_train.shape}')\n",
    "print(f'Test set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Build and Evaluate Predictive Models\n",
    "**Objective:** Train different models and evaluate their performance using various metrics.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Train Logistic Regression and Naive Bayes Models:** Use training data to train the models.\n",
    "2. **Evaluate Model Performance:** Use accuracy, precision, recall, F1 score, and ROC-AUC to evaluate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.33      1.00      0.50         2\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "Naive Bayes Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.33      1.00      0.50         2\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jason\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jason\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jason\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jason\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jason\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Train a Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print('Logistic Regression Classification Report')\n",
    "print(classification_report(y_test, lr_pred))\n",
    "\n",
    "print('Naive Bayes Classification Report')\n",
    "print(classification_report(y_test, nb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. ROC-AUC Analysis\n",
    "**Objective:** Plot ROC curves for different models and calculate the AUC to compare their performance.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Plot ROC Curves:** Visualize the ROC curves for Logistic Regression and Naive Bayes models.\n",
    "2. **Calculate AUC:** Compute the AUC for each model and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true takes value in {'negative', 'positive'} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m lr_probs \u001b[38;5;241m=\u001b[39m lr_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m lr_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, lr_probs)\n\u001b[1;32m----> 4\u001b[0m lr_fpr, lr_tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# ROC-AUC for Naive Bayes\u001b[39;00m\n\u001b[0;32m      7\u001b[0m nb_probs \u001b[38;5;241m=\u001b[39m nb_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_ranking.py:1145\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1044\u001b[0m     {\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m ):\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m \n\u001b[0;32m   1058\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1145\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_ranking.py:834\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    831\u001b[0m     y_score \u001b[38;5;241m=\u001b[39m y_score[nonzero_weight_mask]\n\u001b[0;32m    832\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight[nonzero_weight_mask]\n\u001b[1;32m--> 834\u001b[0m pos_label \u001b[38;5;241m=\u001b[39m \u001b[43m_check_pos_label_consistency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# make y_true a boolean vector\u001b[39;00m\n\u001b[0;32m    837\u001b[0m y_true \u001b[38;5;241m=\u001b[39m y_true \u001b[38;5;241m==\u001b[39m pos_label\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:2503\u001b[0m, in \u001b[0;36m_check_pos_label_consistency\u001b[1;34m(pos_label, y_true)\u001b[0m\n\u001b[0;32m   2495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m classes\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUS\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   2496\u001b[0m         np\u001b[38;5;241m.\u001b[39marray_equal(classes, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m   2497\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(classes, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(classes, [\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m   2501\u001b[0m     ):\n\u001b[0;32m   2502\u001b[0m         classes_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mrepr\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m classes\u001b[38;5;241m.\u001b[39mtolist()])\n\u001b[1;32m-> 2503\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2504\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true takes value in \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mclasses_repr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m and pos_label is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2505\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified: either make y_true take value in \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0, 1} or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2506\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m-1, 1} or pass pos_label explicitly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2507\u001b[0m         )\n\u001b[0;32m   2508\u001b[0m     pos_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pos_label\n",
      "\u001b[1;31mValueError\u001b[0m: y_true takes value in {'negative', 'positive'} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly."
     ]
    }
   ],
   "source": [
    "# ROC-AUC for Logistic Regression\n",
    "lr_probs = lr_model.predict_proba(X_test)[:, 1]\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "\n",
    "# ROC-AUC for Naive Bayes\n",
    "nb_probs = nb_model.predict_proba(X_test)[:, 1]\n",
    "nb_auc = roc_auc_score(y_test, nb_probs)\n",
    "nb_fpr, nb_tpr, _ = roc_curve(y_test, nb_probs)\n",
    "\n",
    "# Plot ROC Curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label=f'Logistic Regression (AUC = {lr_auc:.2f})')\n",
    "plt.plot(nb_fpr, nb_tpr, marker='.', label=f'Naive Bayes (AUC = {nb_auc:.2f})')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Summary and Discussion\n",
    "**Objective:** Reflect on the performance of different models and discuss their implications in the context of text analytics.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Compare Model Performance:** Discuss the results from Logistic Regression and Naive Bayes models, including their ROC-AUC scores.\n",
    "2. **Business Implications:** Describe how evaluating model performance can help improve decision-making in text analytics applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Submission\n",
    "**Deliverables:**\n",
    "- Jupyter Notebook (.ipynb) with all code, visualizations, and model evaluations.\n",
    "- A brief report (1-2 paragraphs) summarizing the findings, comparing model performance, and discussing the use of evaluation metrics in text analytics.\n",
    "\n",
    "**Deadline:** Submit your completed notebook and report to the course portal by the end of class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
