{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 13 Lab Assignment: Social Media Analytics and Trend Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "In this lab, you will apply advanced text mining techniques to analyze social media data, perform trend analysis, and extract meaningful insights. The lab focuses on using advanced sentiment analysis, keyword trend tracking, and topic modeling to understand social media discussions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Installations\n",
    "**Objective:** Ensure all necessary packages are installed and imported for the lab.\n",
    "\n",
    "**Tasks:**\n",
    "1. Install required Python packages: Scikit-learn, Pandas, Numpy, Matplotlib, Seaborn, NLTK, Gensim, TensorFlow, and Tweepy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (1.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (0.13.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (3.9.1)\n",
      "Requirement already satisfied: gensim in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (4.3.3)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (2.17.0)\n",
      "Collecting tweepy\n",
      "  Downloading tweepy-4.14.0-py3-none-any.whl (98 kB)\n",
      "     ---------------------------------------- 98.5/98.5 KB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: click in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (58.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.0)\n",
      "Collecting requests-oauthlib<2,>=1.2.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib<4,>=3.2.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: optree in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: namex in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: rich in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (8.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.2.2 requests-oauthlib-1.3.1 tweepy-4.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'c:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "%pip install scikit-learn pandas numpy matplotlib seaborn nltk gensim tensorflow tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Libraries\n",
    "**Objective:** Import all necessary libraries for data manipulation, text processing, modeling, and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jason\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora, models\n",
    "import tweepy\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Social Media Data Collection\n",
    "**Objective:** Collect data from social media platforms (e.g., Twitter) using APIs.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Set up Twitter API Access:** Use Tweepy to collect tweets based on specific keywords or hashtags.\n",
    "2. **Store Data:** Save the collected tweets into a Pandas DataFrame for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'API' object has no attribute 'search'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m api \u001b[38;5;241m=\u001b[39m tweepy\u001b[38;5;241m.\u001b[39mAPI(auth)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Collect tweets containing a specific hashtag\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m tweets \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m(q\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#DataScience\u001b[39m\u001b[38;5;124m'\u001b[39m, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m tweet_data \u001b[38;5;241m=\u001b[39m [[tweet\u001b[38;5;241m.\u001b[39mtext, tweet\u001b[38;5;241m.\u001b[39mcreated_at] \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tweets]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create a DataFrame\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'API' object has no attribute 'search'"
     ]
    }
   ],
   "source": [
    "# Example code for Twitter data collection using Tweepy\n",
    "# Note: Replace 'your_key' with actual Twitter API credentials\n",
    "consumer_key = 'your_consumer_key'\n",
    "consumer_secret = 'your_consumer_secret'\n",
    "access_token = 'your_access_token'\n",
    "access_token_secret = 'your_access_token_secret'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Collect tweets containing a specific hashtag\n",
    "tweets = api.search(q='#DataScience', count=100, lang='en')\n",
    "tweet_data = [[tweet.text, tweet.created_at] for tweet in tweets]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(tweet_data, columns=['text', 'timestamp'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Text Preprocessing\n",
    "**Objective:** Prepare the social media text data by cleaning and tokenizing it.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Tokenization:** Split text into individual words or tokens.\n",
    "2. **Stop Words Removal:** Use NLTK to remove common stop words from the text.\n",
    "3. **Text Normalization:** Lowercase text, remove punctuation and URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [t for t in tokens if t not in stop_words and t.isalpha()]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "print(df['cleaned_text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Sentiment Analysis\n",
    "**Objective:** Perform sentiment analysis on social media text using a pre-trained deep learning model (e.g., LSTM).\n",
    "\n",
    "**Tasks:**\n",
    "1. **Prepare Data:** Convert text to sequences and split data into training and testing sets.\n",
    "2. **Build and Train Model:** Use LSTM for sentiment classification.\n",
    "3. **Evaluate Model:** Evaluate the model's performance using metrics such as accuracy and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example LSTM model setup for sentiment analysis\n",
    "# Note: This example assumes preprocessed and labeled data (not fully implemented here)\n",
    "max_words = 5000\n",
    "embedding_dim = 50\n",
    "maxlen = 100\n",
    "\n",
    "# Prepare data (pseudocode, replace with actual preprocessing)\n",
    "# X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model (using dummy data for illustration)\n",
    "# history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate model (using dummy data for illustration)\n",
    "# accuracy = model.evaluate(X_test, y_test)[1]\n",
    "# print(f'Model Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Trend Analysis\n",
    "**Objective:** Perform trend analysis on keywords and hashtags to identify popular topics and public sentiment over time.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Keyword Frequency Analysis:** Count the occurrences of specific keywords over time.\n",
    "2. **Visualize Trends:** Plot the frequency of keywords/hashtags to visualize trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of trend analysis using keyword frequency\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Count occurrences of a keyword over time\n",
    "df['keyword_count'] = df['cleaned_text'].str.contains('data').astype(int)\n",
    "keyword_trend = df['keyword_count'].resample('D').sum()\n",
    "\n",
    "# Plot the trend\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(keyword_trend, marker='o', linestyle='-')\n",
    "plt.title('Keyword Trend Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Keyword Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Advanced Topic Modeling\n",
    "**Objective:** Apply advanced topic modeling techniques to analyze social media discussions.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Create Dictionary and Corpus:** Use Gensim to create a dictionary and corpus for topic modeling.\n",
    "2. **Train LDA Model:** Use LDA to find topics within the social media data.\n",
    "3. **Dynamic Topic Modeling:** Analyze the evolution of topics over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and stop words removal for LDA\n",
    "texts = [text.split() for text in df['cleaned_text']]\n",
    "\n",
    "# Create Dictionary and Corpus\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Train LDA Model\n",
    "lda_model = models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)\n",
    "\n",
    "# Display Topics\n",
    "topics = lda_model.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "# Example of Dynamic Topic Modeling (pseudocode, replace with actual implementation)\n",
    "# dynamic_topics = perform_dynamic_topic_modeling(corpus, dictionary, time_slices)\n",
    "# for dynamic_topic in dynamic_topics:\n",
    "#     print(dynamic_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Summary and Discussion\n",
    "**Objective:** Reflect on the use of advanced text mining techniques and discuss their implications in the context of social media analytics.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Compare Techniques:** Discuss the results from sentiment analysis, trend analysis, and topic modeling.\n",
    "2. **Business Implications:** Describe how advanced text mining can provide valuable insights for businesses, such as understanding customer feedback and monitoring public opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Submission\n",
    "**Deliverables:**\n",
    "- Jupyter Notebook (.ipynb) with all code, visualizations, and analysis.\n",
    "- A brief report (1-2 paragraphs) summarizing the findings, including trend analysis results, advanced topic modeling insights, and sentiment analysis outcomes.\n",
    "\n",
    "**Deadline:** Submit your completed notebook and report to the course portal by the end of class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
