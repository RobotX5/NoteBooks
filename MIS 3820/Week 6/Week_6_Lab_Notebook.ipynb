{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Lab Assignment: Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "In this lab, you will implement multiple predictive models and compare their performance using different evaluation metrics. You will learn to select the most appropriate model for a dataset based on these comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Installations\n",
    "**Objective:** Ensure all necessary packages are installed and imported for the lab.\n",
    "\n",
    "**Tasks:**\n",
    "1. Install required Python packages: pandas, scikit-learn, matplotlib, numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (2.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jason\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'c:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "%pip install pandas scikit-learn matplotlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Libraries\n",
    "**Objective:** Import all necessary libraries for data manipulation, modeling, and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and Explore Dataset\n",
    "**Objective:** Gain a preliminary understanding of the dataset to be used for modeling.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Load the Dataset:** Import the dataset into a Pandas DataFrame.\n",
    "2. **Inspect the Data:** Use Pandas functions to inspect the first few rows, check for missing values, and understand the data types.\n",
    "3. **Summary Statistics:** Generate summary statistics for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Income  Number_of_Purchases Customer_Category  Target\n",
      "0   25   50000                    3                 A       0\n",
      "1   45   80000                    8                 B       1\n",
      "2   30   54000                    4                 A       0\n",
      "3   35   60000                    2                 C       1\n",
      "4   50   95000                    7                 B       1\n",
      "Age                    0\n",
      "Income                 0\n",
      "Number_of_Purchases    0\n",
      "Customer_Category      0\n",
      "Target                 0\n",
      "dtype: int64\n",
      "             Age         Income  Number_of_Purchases    Target\n",
      "count  20.000000      20.000000            20.000000  20.00000\n",
      "mean   37.850000   70400.000000             4.750000   0.65000\n",
      "std    10.332753   18871.867115             2.291288   0.48936\n",
      "min    22.000000   49000.000000             1.000000   0.00000\n",
      "25%    29.750000   54750.000000             3.000000   0.00000\n",
      "50%    36.500000   66000.000000             5.000000   1.00000\n",
      "75%    45.250000   80250.000000             6.250000   1.00000\n",
      "max    60.000000  120000.000000             9.000000   1.00000\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('customer_behavior.csv')\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Generate summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Preparation\n",
    "**Objective:** Prepare the data for modeling by handling missing values and encoding categorical variables.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Handle Missing Values:** Deal with any missing values in the dataset.\n",
    "2. **Encode Categorical Variables:** Convert categorical variables into numerical format using techniques like one-hot encoding.\n",
    "3. **Train-Test Split:** Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (14, 5)\n",
      "Test set size: (6, 5)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical variables (if necessary)\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f'Training set size: {X_train.shape}')\n",
    "print(f'Test set size: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Implementing and Evaluating Multiple Models\n",
    "**Objective:** Build and evaluate multiple predictive models on the dataset.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Implement Models:** Create and train logistic regression, decision tree, random forest, and gradient boosting models.\n",
    "2. **Evaluate Models:** Use accuracy, precision, recall, and F1 score to evaluate the models' performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.3333333333333333\n",
      "Logistic Regression Precision: 0.2\n",
      "Logistic Regression Recall: 1.0\n",
      "Logistic Regression F1 Score: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Implementing Logistic Regression\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "logistic_precision = precision_score(y_test, logistic_predictions)\n",
    "logistic_recall = recall_score(y_test, logistic_predictions)\n",
    "logistic_f1 = f1_score(y_test, logistic_predictions)\n",
    "print(f'Logistic Regression Accuracy: {logistic_accuracy}')\n",
    "print(f'Logistic Regression Precision: {logistic_precision}')\n",
    "print(f'Logistic Regression Recall: {logistic_recall}')\n",
    "print(f'Logistic Regression F1 Score: {logistic_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.8333333333333334\n",
      "Decision Tree Precision: 0.5\n",
      "Decision Tree Recall: 1.0\n",
      "Decision Tree F1 Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Implementing Decision Tree\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_predictions = tree_model.predict(X_test)\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "tree_accuracy = accuracy_score(y_test, tree_predictions)\n",
    "tree_precision = precision_score(y_test, tree_predictions)\n",
    "tree_recall = recall_score(y_test, tree_predictions)\n",
    "tree_f1 = f1_score(y_test, tree_predictions)\n",
    "print(f'Decision Tree Accuracy: {tree_accuracy}')\n",
    "print(f'Decision Tree Precision: {tree_precision}')\n",
    "print(f'Decision Tree Recall: {tree_recall}')\n",
    "print(f'Decision Tree F1 Score: {tree_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n",
      "Random Forest Precision: 1.0\n",
      "Random Forest Recall: 1.0\n",
      "Random Forest F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Implementing Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_precision = precision_score(y_test, rf_predictions)\n",
    "rf_recall = recall_score(y_test, rf_predictions)\n",
    "rf_f1 = f1_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "print(f'Random Forest Precision: {rf_precision}')\n",
    "print(f'Random Forest Recall: {rf_recall}')\n",
    "print(f'Random Forest F1 Score: {rf_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.8333333333333334\n",
      "Gradient Boosting Precision: 0.5\n",
      "Gradient Boosting Recall: 1.0\n",
      "Gradient Boosting F1 Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Implementing Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_predictions = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate Gradient Boosting\n",
    "gb_accuracy = accuracy_score(y_test, gb_predictions)\n",
    "gb_precision = precision_score(y_test, gb_predictions)\n",
    "gb_recall = recall_score(y_test, gb_predictions)\n",
    "gb_f1 = f1_score(y_test, gb_predictions)\n",
    "print(f'Gradient Boosting Accuracy: {gb_accuracy}')\n",
    "print(f'Gradient Boosting Precision: {gb_precision}')\n",
    "print(f'Gradient Boosting Recall: {gb_recall}')\n",
    "print(f'Gradient Boosting F1 Score: {gb_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Comparing Model Performance\n",
    "**Objective:** Compare the performance of logistic regression, decision tree, random forest, and gradient boosting models.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Compare Metrics:** Print and compare the accuracy, precision, recall, and F1 scores of all models.\n",
    "2. **Model Selection:** Discuss which model performed best and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.3333333333333333, Precision: 0.2, Recall: 1.0, F1 Score: 0.3333333333333333\n",
      "Decision Tree Accuracy: 0.8333333333333334, Precision: 0.5, Recall: 1.0, F1 Score: 0.6666666666666666\n",
      "Random Forest Accuracy: 1.0, Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Gradient Boosting Accuracy: 0.8333333333333334, Precision: 0.5, Recall: 1.0, F1 Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Compare model performance\n",
    "print(f'Logistic Regression Accuracy: {logistic_accuracy}, Precision: {logistic_precision}, Recall: {logistic_recall}, F1 Score: {logistic_f1}')\n",
    "print(f'Decision Tree Accuracy: {tree_accuracy}, Precision: {tree_precision}, Recall: {tree_recall}, F1 Score: {tree_f1}')\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}, Precision: {rf_precision}, Recall: {rf_recall}, F1 Score: {rf_f1}')\n",
    "print(f'Gradient Boosting Accuracy: {gb_accuracy}, Precision: {gb_precision}, Recall: {gb_recall}, F1 Score: {gb_f1}')\n",
    "\n",
    "# Discuss model performance\n",
    "# (Provide your analysis here based on the results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Using Cross-Validation for Model Evaluation\n",
    "**Objective:** Apply cross-validation to evaluate the stability and reliability of model performance.\n",
    "\n",
    "**Tasks:**\n",
    "1. **Perform Cross-Validation:** Use cross-validation to evaluate the models' performance.\n",
    "2. **Interpret Results:** Analyze cross-validation results to understand model reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jason\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jason\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jason\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jason\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross-Validation Scores: [0.5 1.  1.  1.  1. ]\n",
      "Decision Tree Cross-Validation Scores: [0.75 0.75 1.   1.   1.  ]\n",
      "Random Forest Cross-Validation Scores: [0.75 1.   1.   1.   1.  ]\n",
      "Gradient Boosting Cross-Validation Scores: [0.75 0.75 1.   1.   1.  ]\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "logistic_cv_scores = cross_val_score(logistic_model, X, y, cv=5)\n",
    "tree_cv_scores = cross_val_score(tree_model, X, y, cv=5)\n",
    "rf_cv_scores = cross_val_score(rf_model, X, y, cv=5)\n",
    "gb_cv_scores = cross_val_score(gb_model, X, y, cv=5)\n",
    "\n",
    "# Print cross-validation results\n",
    "print(f'Logistic Regression Cross-Validation Scores: {logistic_cv_scores}')\n",
    "print(f'Decision Tree Cross-Validation Scores: {tree_cv_scores}')\n",
    "print(f'Random Forest Cross-Validation Scores: {rf_cv_scores}')\n",
    "print(f'Gradient Boosting Cross-Validation Scores: {gb_cv_scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Submission\n",
    "**Deliverables:**\n",
    "- Jupyter Notebook (.ipynb) with all code and model evaluations.\n",
    "- A brief report (1-2 paragraphs) summarizing the findings, comparing model performance, and discussing the best model choice based on evaluation metrics and cross-validation results.\n",
    "\n",
    "**Deadline:** Submit your completed notebook and report to the course portal by the end of class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
